"""
BioCoScientist - Main interface for Bio AI Research Assistant
Supports 5 problem types with specialized handlers
"""

import os
import sys
import logging
from typing import Dict, Any, List, Optional
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv

# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë¡œê¹… ì„¤ì • - íŒŒì¼ê³¼ ì½˜ì†” ëª¨ë‘ì— ì¶œë ¥
def setup_logging(experiment_name: Optional[str] = None):
    """
    Set up dual logging configuration (console + full terminal log file).

    Logs are saved to:
    - logs/<project_name_timestamp>/full_terminal.log - All terminal output
    - logs/<project_name_timestamp>/supervisor.log - Essential flow only (managed by SupervisorAgent)

    Args:
        experiment_name: Name of the project (used as directory name in logs/)

    Returns:
        Path: Session directory path (logs/<project_name_timestamp>/)
    """
    # Create session directory: logs/<project_name_timestamp>/
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    if not experiment_name:
        experiment_name = f"experiment_{timestamp}"
    else:
        # Add timestamp to experiment name
        experiment_name = f"{experiment_name}_{timestamp}"

    # Session directory: logs/<project_name_timestamp>/
    session_dir = Path("./logs") / experiment_name
    session_dir.mkdir(parents=True, exist_ok=True)

    # Create RAs subdirectory for RequirementAnswer configs
    ras_dir = session_dir / "RAs"
    ras_dir.mkdir(exist_ok=True)

    # ========== Dual logging: Console + Full Terminal Log ==========
    root_logger = logging.getLogger()
    root_logger.setLevel(logging.INFO)
    root_logger.handlers = []  # Clear existing handlers

    # Console handler - show progress to user
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    console_formatter = logging.Formatter('%(levelname)s - %(message)s')
    console_handler.setFormatter(console_formatter)
    root_logger.addHandler(console_handler)

    # File handler - save all terminal output to full_terminal.log
    terminal_log_file = session_dir / "full_terminal.log"
    file_handler = logging.FileHandler(terminal_log_file, mode='w', encoding='utf-8')
    file_handler.setLevel(logging.INFO)
    file_formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    file_handler.setFormatter(file_formatter)
    root_logger.addHandler(file_handler)

    # ========== Suppress noisy external libraries ==========
    logging.getLogger("httpx").setLevel(logging.ERROR)
    logging.getLogger("httpcore").setLevel(logging.ERROR)

    return session_dir

# Support both relative imports (when used as module) and absolute imports (when run directly)
try:
    from .core import ResearchGoal
    from .agents import SupervisorAgent
    from .tools.registry import ToolRegistry
    from .prompts.prompt_manager import PromptManager
except ImportError:
    # Add parent directory to path for direct execution
    sys.path.insert(0, str(Path(__file__).parent.parent))
    from biocoscientist.core import ResearchGoal
    from biocoscientist.agents import SupervisorAgent
    from biocoscientist.tools.registry import ToolRegistry
    from biocoscientist.prompts.prompt_manager import PromptManager

logger = logging.getLogger(__name__)


class BioCoScientist:
    """
    Bio AI Co-Scientist - Problem-Agnostic Biomedical Research Assistant
    
    New Architecture:
    - Dynamic research planning based on LLM analysis of research goals
    - Adaptive task generation and worker management
    - No predefined problem types - handles any biomedical research question
    """
    
    def __init__(self, config: Optional[Dict[str, Any]] = None, session_dir: Optional[Path] = None):
        """Initialize the Bio AI Co-Scientist system"""
        self.config = config or self.default_config()
        
        # Store session directory for logging
        self.session_dir = session_dir
        if session_dir:
            self.config["session_dir"] = str(session_dir)
        
        # Initialize new supervisor
        self.supervisor = SupervisorAgent(self.config)
        self.logger = logging.getLogger("BioCoScientist")
    
    @staticmethod
    def default_config() -> Dict[str, Any]:
        """Return default configuration"""
        # OpenRouter API í‚¤ ì½ê¸°
        api_key = os.getenv("OPENROUTER_API_KEY")
        if not api_key:
            print("âš ï¸  ê²½ê³ : OPENROUTER_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            print("   .env íŒŒì¼ì— OPENROUTER_API_KEY=your_key_here ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
        
        return {
            "storage_path": "./research_memory",
            "llm": {
                "provider": os.getenv("LLM_PROVIDER", "openrouter"),
                "model": os.getenv("LLM_MODEL", "anthropic/claude-4.5-sonnet"),
                "api_key": api_key,  # í™˜ê²½ë³€ìˆ˜ì—ì„œ ì§ì ‘ ì½ê¸°
                "temperature": 0.7,
                "max_tokens": 8192
            },
            "generation": {
                "techniques": ["data", "assumptions", "expansion"]
            },
            "reflection": {
                "review_types": ["initial", "full", "deep_verification", "observation", "simulation"]
            },
            "ranking": {
                "elo_k_factor": 32,
                "initial_rating": 1200
            },
            "proximity": {
                "similarity_threshold": 0.7
            },
            "evolution": {
                "methods": ["grounding", "coherence", "combination", "simplification", "divergent"]
            },
            "meta_review": {
                "overview_format": "standard"
            }
        }

    async def research_from_file(self, problem_file: str, **kwargs) -> Dict[str, Any]:
        """Start research directly from a problem file.
        
        Args:
            problem_file: Path to the problem description file
            **kwargs: Additional research parameters (max_iterations, etc.)
        
        Returns:
            Research results
        """
        # Read problem file
        with open(problem_file, 'r', encoding='utf-8') as f:
            problem_text = f.read()
        
        # Create a simple research goal - ConfigurationAgent will do the detailed parsing
        research_goal = ResearchGoal(
            description=problem_text.strip(),
            domain="Biomedical Research",
            focus_areas=[],  # ConfigurationAgent will extract these
            constraints={},
            success_criteria=[],
            metadata={"source_file": problem_file}
        )
        
        # Run Sequential Confirmation research
        user_preferences = {
            "max_iterations": kwargs.get("max_iterations", 3)
        }

        results = await self.supervisor.run_sequential_confirmation(
            research_goal=research_goal,
            user_preferences=user_preferences
        )

        return results

    def get_confirmed_answers(self) -> Dict[str, Any]:
        """Get all confirmed RequirementAnswers"""
        return self.supervisor.memory.get_all_confirmed_answers()

    def get_best_answers(self) -> Dict[str, Any]:
        """Get the best answer for each requirement"""
        return self.supervisor.memory.get_best_answer_per_requirement()
    
    async def parse_problem_file(self, file_path: str) -> Dict[str, Any]:
        """
        Parse a problem description file and extract research parameters dynamically.
        
        Args:
            file_path: Path to the problem description file
        
        Returns:
            Dictionary with goal_description, domain, focus_areas, constraints, success_criteria
        """
        self.logger.info(f"Parsing problem file: {file_path}")
        
        # Read file content
        with open(file_path, 'r', encoding='utf-8') as f:
            problem_text = f.read()
        
        # Use LLM to extract structured information
        try:
            from .external_apis import LLMClient
        except ImportError:
            from biocoscientist.external_apis import LLMClient
        
        llm_config = self.config.get("llm", {})
        
        # API í‚¤ ê°€ì ¸ì˜¤ê¸° - configì—ì„œ ì´ë¯¸ í™˜ê²½ë³€ìˆ˜ ì½ì–´ì„œ ì €ì¥ë¨
        api_key = llm_config.get("api_key")
        if not api_key:
            self.logger.warning("No API key available, using basic parsing")
            return {
                "goal_description": problem_text.strip(),
                "domain": "Biomedical Research",
                "focus_areas": ["Analysis", "Research"],
                "constraints": {},
                "success_criteria": ["Complete analysis"],
                "metadata": {}
            }
        
        try:
            llm_client = LLMClient(
                provider=llm_config.get("provider"),
                model=llm_config.get("model"),
                api_key=api_key,
                temperature=llm_config.get("temperature", 0.7),
                max_tokens=llm_config.get("max_tokens", 8192)
            )
        except Exception as e:
            print(f"[DEBUG] LLMClient creation failed: {e}")
            raise
        
        extraction_prompt = f"""
ë‹¹ì‹ ì€ ìƒë¬¼ì˜í•™ ì—°êµ¬ ë¬¸ì œë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì•„ë˜ ë¬¸ì œ ì„¤ëª…ì„ ì½ê³ , BioCoScientist ì‹œìŠ¤í…œì— ì…ë ¥í•  êµ¬ì¡°í™”ëœ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

ë¬¸ì œ ì„¤ëª…:
{problem_text}

ë‹¤ìŒ í˜•ì‹ì˜ JSONìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{{
  "goal_description": "ì—°êµ¬ ëª©í‘œë¥¼ 1-2ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½",
  "domain": "ì—°êµ¬ ë„ë©”ì¸ (ì˜ˆ: Protein Engineering, Drug Discovery, Systems Biology ë“±)",
  "focus_areas": ["êµ¬ì²´ì ì¸ ì—°êµ¬ ì˜ì—­ 1", "êµ¬ì²´ì ì¸ ì—°êµ¬ ì˜ì—­ 2", ...],
  "constraints": {{
    "ì œì•½ì¡°ê±´ í‚¤1": "ê°’1",
    "ì œì•½ì¡°ê±´ í‚¤2": "ê°’2"
  }},
  "success_criteria": ["ì„±ê³µ ê¸°ì¤€ 1", "ì„±ê³µ ê¸°ì¤€ 2", ...]
}}

ì£¼ì˜ì‚¬í•­:
- goal_descriptionì€ í•µì‹¬ ëª©í‘œë§Œ ê°„ê²°í•˜ê²Œ
- focus_areasëŠ” 3-5ê°œ ì •ë„ì˜ êµ¬ì²´ì ì¸ ì˜ì—­
- constraintsëŠ” ë¬¸ì œì—ì„œ ëª…ì‹œëœ ì œì•½ì¡°ê±´ì´ë‚˜ ìš”êµ¬ì‚¬í•­
- success_criteriaëŠ” ë³´ê³ ì„œì— í¬í•¨ë  ë‚´ìš©ì´ ë‹¤ í¬í•¨ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ëŠ” ê¸°ì¤€
"""
        
        try:
            result = await llm_client.generate_json(
                messages=[{"role": "user", "content": extraction_prompt}],
                system="You are an expert in biomedical research problem analysis. Extract structured information accurately."
            )
            
            # Ensure metadata field exists
            if "metadata" not in result:
                result["metadata"] = {}
            
            self.logger.info("Successfully parsed problem file")
            self.logger.debug(f"Extracted: {result}")
            
            return result
            
        except Exception as e:
            self.logger.error(f"Failed to parse problem file with LLM: {e}")
            # Fallback to basic extraction
            return {
                "goal_description": problem_text.strip(),
                "domain": "Biomedical Research",
                "focus_areas": ["Analysis", "Research"],
                "constraints": {},
                "success_criteria": ["Complete analysis"],
                "metadata": {}
            }
    
    def export_results(self, results: Dict[str, Any], output_path: str) -> None:
        """Export research results to file with full memory data for report generation"""
        import json
        from pathlib import Path

        # Get full memory data for comprehensive report generation
        memory_data = self.supervisor.memory.export_to_dict()

        # Convert results to exportable format
        export_data = {
            "research_config": results.get("research_config", {}),
            "final_metrics": results.get("final_metrics", {}),
            "top_hypotheses": results.get("top_hypotheses", []),
            "execution_stats": results.get("execution_stats", {}),
            "research_goal": {
                "description": getattr(self, 'research_goal', ResearchGoal(description="")).description,
                "domain": getattr(self, 'research_goal', ResearchGoal(description="")).domain
            },
            # Full memory data for ReportGenerator
            "hypotheses": memory_data.get("hypotheses", []),
            "reviews": memory_data.get("reviews", []),
            "overviews": memory_data.get("overviews", []),
            "tournament_matches": memory_data.get("tournament_matches", []),
            "meta_reviews": memory_data.get("meta_reviews", [])
        }

        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, indent=2, ensure_ascii=False, default=str)

        self.logger.info(f"Results exported to {output_path}")
        self.logger.info(f"  - {len(export_data['hypotheses'])} hypotheses")
        self.logger.info(f"  - {len(export_data['reviews'])} reviews")
        self.logger.info(f"  - {len(export_data['overviews'])} overviews")
        
        # ë³´ê³ ì„œ ìë™ ìƒì„±
        try:
            from biocoscientist.utils.report_generator import (
                generate_final_research_report,
                generate_report_from_json
            )

            # reports í´ë” ê²½ë¡œ ìƒì„±
            reports_dir = Path("reports")
            reports_dir.mkdir(exist_ok=True)

            # íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„±
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

            # íŒŒì¼ëª… í˜•ì‹: BioCoScientist_Report_research_{timestamp}
            report_name = f"BioCoScientist_Report_research_{timestamp}"

            # â˜… NEW: ìµœê³  ê°€ì„¤ ì¤‘ì‹¬ ì—°êµ¬ ë³´ê³ ì„œ ìƒì„± (Markdown)
            # results dictì—ì„œ ì§ì ‘ best_hypothesis ë“± í™•ì¥ ë°ì´í„° ì‚¬ìš©
            final_report_path = str(reports_dir / f"{report_name}_FINAL.md")
            generate_final_research_report(results, final_report_path)
            self.logger.info(f"Final research report generated: {final_report_path}")

            # Legacy: í†µê³„ ì¤‘ì‹¬ ë³´ê³ ì„œ (ê¸°ì¡´ í˜•ì‹ ìœ ì§€)
            legacy_report_path = str(reports_dir / f"{report_name}_statistics.txt")
            generate_report_from_json(output_path, legacy_report_path, "full")
            self.logger.info(f"Statistics report generated: {legacy_report_path}")

            print(f"\nğŸ“Š Reports Generated:")
            print(f"  - ğŸ“„ Final Research Report: {final_report_path}")
            print(f"  - ğŸ“ˆ Statistics Report: {legacy_report_path}")

        except Exception as e:
            self.logger.error(f"Failed to generate reports: {e}")
            print(f"âš ï¸  Report generation failed: {e}")


# ============================================================================
# Main Execution
# ============================================================================

async def main(problem_file: str, session_dir: Path):
    """
    Main execution function - simplified to just run research from file

    Args:
        problem_file: Path to problem description file
        session_dir: Session directory for logs (created by setup_logging)
    """
    # Create BioCoScientist instance with provided session_dir
    bio_coscientist = BioCoScientist(session_dir=session_dir)
    
    # Run research from file - ConfigurationAgent handles all parsing
    results = await bio_coscientist.research_from_file(problem_file)
    
    # Display results
    print("\n" + "="*80)
    print("âœ… RESEARCH COMPLETE")
    print("="*80)
    
    final_metrics = results.get('final_metrics', {})
    execution_stats = results.get('execution_stats', {})
    
    print(f"\nğŸ“Š Research Metrics:")
    print(f"  Total Hypotheses: {final_metrics.get('total_hypotheses', 0)}")
    print(f"  Reviewed: {final_metrics.get('reviewed_hypotheses', 0)}")
    print(f"  Passed Review: {final_metrics.get('passed_hypotheses', 0)}")
    print(f"  Average ELO: {final_metrics.get('avg_elo_rating', 0):.1f}")
    
    print(f"\nâš™ï¸ Execution Stats:")
    print(f"  Iterations: {execution_stats.get('iterations', 0)}")
    print(f"  Duration: {execution_stats.get('duration_seconds', 0):.1f}s")
    
    # Export results
    bio_coscientist.export_results(results, "research_results.json")


if __name__ == "__main__":
    import asyncio
    import sys
    
    if len(sys.argv) < 2:
        print("\nâš ï¸  Usage: python biocoscientist.py <problem_file.txt>")
        print("   Example: python biocoscientist.py problems/minibinder_design.txt")
        sys.exit(1)
    
    problem_file = sys.argv[1]
    
    # Extract project name from problem file and setup logging
    project_name = Path(problem_file).stem
    session_dir = setup_logging(experiment_name=project_name)

    print(f"\nğŸ“ Project: {project_name}")
    print(f"ğŸ“‚ Session directory: {session_dir}")
    print(f"ğŸ“ Logs:")
    print(f"   - Full terminal: {session_dir / 'full_terminal.log'}")
    print(f"   - Supervisor:    {session_dir / 'supervisor.log'}")
    print(f"âš™ï¸  Config: {session_dir / 'config.json'}\n")

    asyncio.run(main(problem_file, session_dir))
